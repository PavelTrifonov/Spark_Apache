{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import sum, window, when, col\n",
    "from pyspark.sql.types import TimestampType\n",
    "\n",
    "# Создание сессии Spark\n",
    "spark = SparkSession.builder.appName(\"HomeWork_04\").getOrCreate()\n",
    "\n",
    "# Чтение данных из потокового источника 'rate'\n",
    "df = spark.readStream.format(\"rate\") \\\n",
    "    .option(\"rowsPerSecond\", 1) \\\n",
    "    .option(\"numPartitions\", 4) \\\n",
    "    .option(\"maxRecordsPerTrigger\", 50) \\\n",
    "    .load()\n",
    "\n",
    "\n",
    "# Преобразование типа данных столбца timestamp к типу TimestampType, если это необходимо\n",
    "if df.schema[\"timestamp\"].dataType != TimestampType():\n",
    "    df = df.withColumn(\"timestamp\", df[\"timestamp\"].cast(TimestampType()))\n",
    "\n",
    "# Определение водяного знака (watermark)\n",
    "windowed_df = df.withWatermark(\"timestamp\", \"10 seconds\")\n",
    "\n",
    "# Определение интервала оконной функции\n",
    "window_spec = window(windowed_df.timestamp, \"10 seconds\")\n",
    "\n",
    "# Расчет суммы нечетных значений в окне\n",
    "sum_df = windowed_df.groupBy(window_spec).agg(sum(when(col(\"value\") % 2 != 0, col(\"value\"))).alias(\"sum_odd\"))\n",
    "\n",
    "# Начать потоковый запрос\n",
    "query = sum_df.writeStream.outputMode(\"append\").format(\"memory\").queryName(\"CountElements\").start()\n",
    "\n",
    "# Дождитесь завершения\n",
    "query.awaitTermination(500)\n",
    "query.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+\n",
      "|              window|sum_odd|\n",
      "+--------------------+-------+\n",
      "|{2024-05-02 22:27...|    515|\n",
      "|{2024-05-02 22:27...|    565|\n",
      "|{2024-05-02 22:26...|    265|\n",
      "|{2024-05-02 22:26...|    315|\n",
      "|{2024-05-02 22:25...|    115|\n",
      "|{2024-05-02 22:25...|     65|\n",
      "|{2024-05-02 22:26...|    215|\n",
      "|{2024-05-02 22:25...|     16|\n",
      "|{2024-05-02 22:26...|    415|\n",
      "|{2024-05-02 22:26...|    365|\n",
      "|{2024-05-02 22:27...|    615|\n",
      "|{2024-05-02 22:26...|    465|\n",
      "|{2024-05-02 22:25...|    165|\n",
      "+--------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM CountElements\").show(200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
